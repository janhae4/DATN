services:
  rabbitmq:
    image: rabbitmq:management
    hostname: "rabbitmq"
    container_name: rabbitmq_broker
    ports:
      - "5672:5672" 
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq

  redis:
    image: redis:alpine
    hostname: "redis"
    container_name: redis_backend
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

  postgres:
    image: postgres:alpine
    hostname: "postgres"
    container_name: postgres_backend
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgres-init:/docker-entrypoint-initdb.d

  mongo:
    image: mongo:8.0
    hostname: "mongo"
    container_name: mongo_db
    restart: unless-stopped     
    ports:
      - "27017:27017"         
    environment:
      - MONGO_INITDB_ROOT_USERNAME=mongo
      - MONGO_INITDB_ROOT_PASSWORD=mongo
    volumes:
      - mongo-data:/data/db


  worker:
    build: 
      context: ./python/ner-service
      dockerfile: Dockerfile
    
    container_name: task_ner

    command: ["python", "main.py"]
    
    volumes:
      - ./python/ner-service:/app
    
    ports:
      - "4002:4002"
      
    environment:
      RABBITMQ_HOST: rabbitmq
      QUEUE_NAME: process_nlp
      
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_started

  chatbot: 
    build: 
      context: ./python/chatbot-service
    container_name: rag_chatbot
    command: ["python", "main.py"]
    volumes:
      - ./python/chatbot-service:/app
    ports:
      - "4003:4003"
    environment:
      RABBITMQ_HOST: rabbitmq
      QUEUE_NAME: process_chatbot
        
  ollama:
    image: ollama/ollama
    container_name: ollama_service
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
      - ./init-ollama.sh:/init-ollama.sh
    entrypoint: ["/bin/sh", "/init-ollama.sh"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
volumes:
  postgres-data:
  redis-data:
  rabbitmq-data:
  ollama-data:
  mongo-data: