'use client';

import React, { useState, useRef, useEffect } from 'react';
import { useParams, useRouter } from 'next/navigation';
import { ControlsBar } from '@/components/features/meeting/ControlsBar';
import { VideoGrid } from '@/components/features/meeting/VideoGrid';
import { useWebRTC } from '@/hooks/useWebRTC';
import { useSpeechRecognition } from '@/hooks/useSpeechRecognition';
import { MeetingHeader } from '@/components/features/meeting/MeetingHeader';
// Import Component m·ªõi t·∫°o
import { TranscriptPanel, TranscriptMessage } from '@/components/features/meeting/TranscriptPanel';

export default function MeetingRoomPage() {
  const params = useParams();
  const router = useRouter();
  const roomId = params.roomId as string;
  
  // Custom hooks
  const { localStream, remoteStreams, peerNames, socket } = useWebRTC(roomId);
  
  // UI State
  const [isMicOn, setIsMicOn] = useState(true);
  const [isCamOn, setIsCamOn] = useState(true);
  const [peerCamStates, setPeerCamStates] = useState<Map<string, boolean>>(new Map());
  
  // --- NEW: State cho Transcript Panel ---
  const [showTranscript, setShowTranscript] = useState(false);
  const [transcripts, setTranscripts] = useState<TranscriptMessage[]>([]);

  // 1. Logic x·ª≠ l√Ω socket nh·∫≠n transcript t·ª´ ng∆∞·ªùi kh√°c
  useEffect(() => {
    if (!socket) return;

    // L·∫Øng nghe s·ª± ki·ªán 'transcript_received' t·ª´ server
    // (Gi·∫£ ƒë·ªãnh server emit event n√†y khi c√≥ ai ƒë√≥ g·ª≠i transcript)
    const handleTranscriptReceived = (data: any) => {
      const newMessage: TranscriptMessage = {
        id: Date.now().toString() + Math.random(), // Fallback ID
        userId: data.userId,
        userName: peerNames.get(data.userId) || 'Unknown', // Map t√™n t·ª´ ID n·∫øu c√≥
        content: data.content,
        timestamp: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
      };
      
      setTranscripts((prev) => [...prev, newMessage]);
    };

    socket.on('transcript_received', handleTranscriptReceived);

    return () => {
      socket.off('transcript_received', handleTranscriptReceived);
    };
  }, [socket, peerNames]);

  // 2. X·ª≠ l√Ω khi Speech Recognition nh·∫≠n di·ªán gi·ªçng n√≥i local
  const handleSpeechResult = (text: string) => {
    console.log("üó£Ô∏è User said:", text);
    const userId = 'CURRENT_USER_ID'; // L·∫•y t·ª´ auth context th·ª±c t·∫ø c·ªßa b·∫°n

    // Emit l√™n server
    socket?.emit('send_transcript', {
      content: text,
      roomId: roomId,
      userId: userId
    });

    // C·∫≠p nh·∫≠t UI ngay l·∫≠p t·ª©c (Optimistic Update) ƒë·ªÉ ng∆∞·ªùi d√πng th·∫•y m√¨nh v·ª´a n√≥i
    const myMessage: TranscriptMessage = {
      id: Date.now().toString(),
      userId: userId,
      userName: 'B·∫°n',
      content: text,
      timestamp: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
    };
    setTranscripts(prev => [...prev, myMessage]);
  };

  const { isListening, startListening, stopListening } = useSpeechRecognition(handleSpeechResult);

  // 3. Toggle Panel Transcript
  const toggleTranscriptPanel = () => {
    const newState = !showTranscript;
    setShowTranscript(newState);
    
    // Logic ph·ª•: T·ª± ƒë·ªông b·∫≠t/t·∫Øt nh·∫≠n di·ªán gi·ªçng n√≥i khi m·ªü/ƒë√≥ng panel (Tu·ª≥ ch·ªçn UX)
    // N·∫øu mu·ªën t√°ch bi·ªát (n√∫t b·∫≠t panel ri√™ng, n√∫t b·∫≠t mic ri√™ng) th√¨ b·ªè ƒëo·∫°n n√†y ƒëi.
    if (newState && !isListening) {
      startListening();
    } else if (!newState && isListening) {
      stopListening();
    }
  };

  const toggleMic = () => {
    if (localStream) {
      localStream.getAudioTracks().forEach(track => track.enabled = !isMicOn);
      setIsMicOn(!isMicOn);
    }
  };

  const toggleCam = () => {
    if (localStream) {
      localStream.getVideoTracks().forEach(track => track.enabled = !isCamOn);
      setIsCamOn(!isCamOn);
    }
  };

  const leaveRoom = () => {
    router.push(`/${params.teamId}/meeting`);
  };

  return (
    <div className="flex flex-col h-screen bg-neutral-900 text-white overflow-hidden">
      
      {/* Header lu√¥n c·ªë ƒë·ªãnh ·ªü tr√™n */}
      <MeetingHeader roomId={roomId} participantCount={remoteStreams.size + 1} />

      {/* Main Content: D√πng flex-1 ƒë·ªÉ chi·∫øm to√†n b·ªô chi·ªÅu cao c√≤n l·∫°i */}
      {/* Flex Row ƒë·ªÉ VideoGrid v√† TranscriptPanel n·∫±m ngang nhau */}
      <div className="flex flex-1 overflow-hidden relative">
        
        {/* VideoGrid Area: Chi·∫øm ph·∫ßn c√≤n l·∫°i */}
        <div className={`flex-1 transition-all duration-300 ${showTranscript ? 'mr-0' : ''}`}>
           <VideoGrid
            localStream={localStream}
            remoteStreams={remoteStreams}
            peerNames={peerNames}
            isMicOn={isMicOn}
            isCamOn={isCamOn}
            peerCamStates={peerCamStates}
          />
        </div>

        {/* Transcript Panel (Sidebar) */}
        <TranscriptPanel 
          isOpen={showTranscript} 
          onClose={() => setShowTranscript(false)}
          messages={transcripts}
        />
        
      </div>

      {/* Controls Bar lu√¥n c·ªë ƒë·ªãnh ·ªü d∆∞·ªõi */}
      <ControlsBar
        isMicOn={isMicOn}
        isCamOn={isCamOn}
        // Button n√†y gi·ªù s·∫Ω b·∫≠t/t·∫Øt Panel hi·ªÉn th·ªã
        isTranscriptOn={showTranscript} 
        onToggleMic={toggleMic}
        onToggleCam={toggleCam}
        // Logic: Click n√∫t -> Toggle Panel (v√† trigger speech recognition b√™n trong h√†m toggle)
        onToggleTranscript={toggleTranscriptPanel} 
        onLeave={leaveRoom}
      />
    </div>
  );
}